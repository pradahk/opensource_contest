import React, { useState, useEffect, useRef } from 'react';
import { useParams, useNavigate } from 'react-router-dom';
import { aiInterviewAPI } from '../services/api';
import Layout from '../components/Layout';
import '../styles/AIInterviewRoom.css';

const AIInterviewRoom = () => {
  const { sessionId } = useParams();
  const navigate = useNavigate();
  const [session, setSession] = useState(null);
  const [currentQuestion, setCurrentQuestion] = useState(null);
  const [isRecording, setIsRecording] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const [transcription, setTranscription] = useState('');
  const [error, setError] = useState(null);
  const [loading, setLoading] = useState(true);
  const [threadId, setThreadId] = useState(null);
  const [aiResponse, setAiResponse] = useState('');
  const [aiAudioUrl, setAiAudioUrl] = useState(null);
  const [isInitialized, setIsInitialized] = useState(false);
  const [interviewLog, setInterviewLog] = useState([]);
  const MAX_TOTAL_QUESTIONS = 15;
  const recordStartedAtRef = useRef(null);
  
  // ìƒˆë¡œìš´ ìƒíƒœ ì¶”ê°€
  const [interviewStage, setInterviewStage] = useState('self_introduction_request'); // ë©´ì ‘ ë‹¨ê³„
  const [questionCount, setQuestionCount] = useState(0); // ì§ˆë¬¸ ì¹´ìš´íŠ¸
  const [followUpCount, setFollowUpCount] = useState(0); // ê¼¬ë¦¬ì§ˆë¬¸ ì¹´ìš´íŠ¸
  const [hasSelfIntroduction, setHasSelfIntroduction] = useState(false); // ìê¸°ì†Œê°œ ì™„ë£Œ ì—¬ë¶€
  const [isInterviewEnded, setIsInterviewEnded] = useState(false); // ë©´ì ‘ ì¢…ë£Œ ì—¬ë¶€
  
  const mediaRecorderRef = useRef(null);
  const audioChunksRef = useRef([]);
  const recognitionRef = useRef(null);
  const initializationRef = useRef(false);

  useEffect(() => {
    if (sessionId && !isInitialized && !initializationRef.current) {
      console.log('AI ì¸í„°ë·° ì´ˆê¸°í™” ì‹œì‘ - sessionId:', sessionId);
      initializationRef.current = true;
      setIsInitialized(true);
      initializeSession();
      initializeSpeechRecognition();
    }
    
    return () => {
      initializationRef.current = false;
    };
  }, [sessionId]);

  const initializeSession = async () => {
    try {
      setLoading(true);
      setError(null);
      console.log('AI ì¸í„°ë·° ì„¸ì…˜ ì´ˆê¸°í™” ì‹œì‘');
      
      // AI ì¸í„°ë·° ì„¸ì…˜ ì‹œì‘ (ìê¸°ì†Œê°œ ìš”ì²­ë¶€í„°)
      const response = await aiInterviewAPI.startSession({
        userId: localStorage.getItem('user') ? JSON.parse(localStorage.getItem('user')).id : null,
        companyId: localStorage.getItem('ai_selected_company_id') || null,
        position: 'ê°œë°œì',
        includeInitialQuestion: true
      });
      
      console.log('AI ì¸í„°ë·° ì„¸ì…˜ ì‘ë‹µ:', response);
      
      if (response.success) {
        const newThreadId = response.thread_id;
        setThreadId(newThreadId);
        setSession({ id: sessionId, thread_id: newThreadId });
        
        // ì‘ì—… 0: ìê¸°ì†Œê°œ ìš”ì²­ìœ¼ë¡œ ì‹œì‘
        await requestSelfIntroduction(newThreadId);
      } else {
        throw new Error(response.message || 'ì„¸ì…˜ì„ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
      }
    } catch (err) {
      console.error('Error initializing session:', err);
      
      if (err.response) {
        const errorMessage = err.response.data?.message || err.response.data?.error || 'ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.';
        setError(`ì„¸ì…˜ ì´ˆê¸°í™” ì‹¤íŒ¨: ${errorMessage}`);
      } else if (err.request) {
        setError('ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.');
      } else {
        setError(`ì„¸ì…˜ì„ ì´ˆê¸°í™”í•˜ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: ${err.message}`);
      }
    } finally {
      setLoading(false);
    }
  };

  // ì‘ì—… 0: ìê¸°ì†Œê°œ ìš”ì²­
  const requestSelfIntroduction = async (threadId) => {
    try {
      console.log('ìê¸°ì†Œê°œ ìš”ì²­ ì‹œì‘');
      
      const response = await aiInterviewAPI.generateQuestion({
        task_type: 'self_introduction_request',
        company_id: localStorage.getItem('ai_selected_company_id') || null,
        thread_id: threadId
      });
      
      if (response.success) {
        setCurrentQuestion({
          question_text: response.data.question_text,
          question_type: response.data.question_type,
          question_number: 0
        });
        setAiResponse(response.data.question_text);
        setInterviewStage('self_introduction_request');
        setQuestionCount(0);
        
        // AI ìŒì„± ì„¤ì •
        if (response.audioContent) {
          const audioBlob = new Blob(
            [Uint8Array.from(atob(response.audioContent), c => c.charCodeAt(0))],
            { type: 'audio/mp3' }
          );
          const audioUrl = URL.createObjectURL(audioBlob);
          setAiAudioUrl(audioUrl);
        }
      } else {
        throw new Error(response.error || 'ìê¸°ì†Œê°œ ìš”ì²­ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
      }
    } catch (err) {
      console.error('ìê¸°ì†Œê°œ ìš”ì²­ ì˜¤ë¥˜:', err);
      setError('ìê¸°ì†Œê°œ ìš”ì²­ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
    }
  };

  const initializeSpeechRecognition = () => {
    if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      recognitionRef.current = new SpeechRecognition();
      recognitionRef.current.continuous = true;
      recognitionRef.current.interimResults = true;
      recognitionRef.current.lang = 'ko-KR';

      recognitionRef.current.onresult = (event) => {
        let finalTranscript = '';
        let interimTranscript = '';

        for (let i = event.resultIndex; i < event.results.length; i++) {
          const transcript = event.results[i][0].transcript;
          if (event.results[i].isFinal) {
            finalTranscript += transcript;
          } else {
            interimTranscript += transcript;
          }
        }

        setTranscription(finalTranscript + interimTranscript);
      };

      recognitionRef.current.onerror = (event) => {
        console.error('Speech recognition error:', event.error);
        setError('ìŒì„± ì¸ì‹ì— ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
      };
    } else {
      setError('ì´ ë¸Œë¼ìš°ì €ëŠ” ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.');
    }
  };

  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      mediaRecorderRef.current = new MediaRecorder(stream);
      audioChunksRef.current = [];

      mediaRecorderRef.current.ondataavailable = (event) => {
        audioChunksRef.current.push(event.data);
      };

      mediaRecorderRef.current.onstop = () => {
        const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/wav' });
        handleAnswerSubmission(audioBlob);
      };

      mediaRecorderRef.current.start();
      recordStartedAtRef.current = Date.now();
      setIsRecording(true);
      setTranscription('');
      
      if (recognitionRef.current) {
        recognitionRef.current.start();
      }
    } catch (err) {
      setError('ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.');
      console.error('Error starting recording:', err);
    }
  };

  const stopRecording = () => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop();
      setIsRecording(false);
      
      
      if (recognitionRef.current) {
        recognitionRef.current.stop();
      }
    }
  };

  const handleAnswerSubmission = async (audioBlob) => {
    try {
      setIsProcessing(true);
      setError(null);

      console.log('=== ë‹µë³€ ì²˜ë¦¬ ì‹œì‘ ===');
      console.log('Thread ID:', threadId);
      console.log('í˜„ì¬ ë©´ì ‘ ë‹¨ê³„:', interviewStage);
      console.log('ì§ˆë¬¸ ì¹´ìš´íŠ¸:', questionCount);

      // ìŒì„± ì¸ì‹ (STT)
      console.log('ìŒì„± ì¸ì‹ ìš”ì²­ ì¤‘...');
      const transcribeResponse = await aiInterviewAPI.transcribeAudio(audioBlob);
      console.log('ìŒì„± ì¸ì‹ ì‘ë‹µ:', transcribeResponse);
      
      if (!transcribeResponse.success) {
        throw new Error(transcribeResponse.error || 'ìŒì„± ì¸ì‹ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
      }

      const userTranscription = transcribeResponse.transcription;
      console.log('=== ì‚¬ìš©ì ìŒì„± ì¸ì‹ ê²°ê³¼ ===');
      console.log('ì‚¬ìš©ì ì‘ë‹µ:', userTranscription);
      setTranscription(userTranscription);

      // ê°„ì´ ìŒì„± ì§€í‘œ ê³„ì‚°
      const startedAt = recordStartedAtRef.current || Date.now();
      const durationMs = Math.max(1, Date.now() - startedAt);
      const durationMin = durationMs / 60000;
      const words = (userTranscription || '').trim().split(/\s+/).filter(Boolean).length;
      const speedWpm = Math.max(1, Math.round(words / (durationMin || 1)));
      const fillerCount = (userTranscription.match(/\b(ìŒ|ì–´|ê·¸|ìŒ...|ì–´..|ê·¸..|uh|um)\b/g) || []).length;
      const senseVoice = {
        pronunciation_score: null,
        emotion: 'neutral',
        speed_wpm: speedWpm,
        filler_count: fillerCount,
        pitch_variation: null,
      };

      // ë¡œê·¸ì— ê¸°ë¡ (ì§ˆë¬¸/ë‹µë³€/ìŒì„±ì§€í‘œ)
      if (currentQuestion?.question_text) {
        setInterviewLog(prev => ([
          ...prev,
          {
            question_text: currentQuestion.question_text,
            transcription: userTranscription,
            sense_voice_analysis: senseVoice,
          }
        ]));
      }

      // ë©´ì ‘ ë‹¨ê³„ì— ë”°ë¥¸ ì²˜ë¦¬
      if (interviewStage === 'self_introduction_request') {
        // ìê¸°ì†Œê°œ ì™„ë£Œ í›„ ì²« ë²ˆì§¸ ì§ˆë¬¸ìœ¼ë¡œ
        setHasSelfIntroduction(true);
        setInterviewStage('initial_question');
        setQuestionCount(1);
        await generateNextQuestion(userTranscription, 'initial_question');
      } else {
        // ì¼ë°˜ì ì¸ ë‹µë³€ ì²˜ë¦¬
        await generateNextQuestion(userTranscription, 'next_question');
      }
      
      console.log('=== ë‹µë³€ ì²˜ë¦¬ ì™„ë£Œ ===');
    } catch (err) {
      console.error('=== ë‹µë³€ ì²˜ë¦¬ ì˜¤ë¥˜ ===');
      console.error('ì˜¤ë¥˜ íƒ€ì…:', err.constructor.name);
      console.error('ì˜¤ë¥˜ ë©”ì‹œì§€:', err.message);
      console.error('ì˜¤ë¥˜ ìŠ¤íƒ:', err.stack);
      
      if (err.response) {
        console.error('ì‘ë‹µ ìƒíƒœ:', err.response.status);
        console.error('ì‘ë‹µ ë°ì´í„°:', err.response.data);
        const errorMessage = err.response.data?.error || err.response.data?.message || 'ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.';
        setError(`ë‹µë³€ ì²˜ë¦¬ ì‹¤íŒ¨: ${errorMessage}`);
      } else if (err.request) {
        console.error('ìš”ì²­ ì˜¤ë¥˜:', err.request);
        setError('ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.');
      } else {
        setError(`ë‹µë³€ì„ ì²˜ë¦¬í•˜ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: ${err.message}`);
      }
    } finally {
      setIsProcessing(false);
    }
  };

  // ë‹¤ìŒ ì§ˆë¬¸ ìƒì„±
  const generateNextQuestion = async (transcription, taskType) => {
    try {
      console.log('ë‹¤ìŒ ì§ˆë¬¸ ìƒì„± ì‹œì‘:', { taskType, questionCount });
      
      const response = await aiInterviewAPI.generateQuestion({
        task_type: taskType,
        company_id: localStorage.getItem('ai_selected_company_id') || null,
        question_text: currentQuestion?.question_text || '',
        transcription: transcription,
        thread_id: threadId,
        current_question_count: questionCount,
        follow_up_count: followUpCount
      });
      
      if (response.success) {
        // ë©´ì ‘ ì¢…ë£Œ í™•ì¸
        if (response.data.is_end) {
          setIsInterviewEnded(true);
          // ë§ˆì§€ë§‰ ë¬¸ì œ í‘œê¸°ë¥¼ 15ë¡œ ê³ ì •
          setQuestionCount(MAX_TOTAL_QUESTIONS);
          setCurrentQuestion({
            question_text: response.data.question_text,
            question_type: response.data.question_type,
            question_number: MAX_TOTAL_QUESTIONS
          });
          setAiResponse(response.data.question_text);
          setInterviewStage('final');
          
          // 3ì´ˆ í›„ ë©´ì ‘ ì¢…ë£Œ
          setTimeout(() => {
            handleEndInterview();
          }, 2000);
          return;
        }
        
        // ê¼¬ë¦¬ì§ˆë¬¸ íšŸìˆ˜ ì—…ë°ì´íŠ¸
        if (response.data.is_follow_up) {
          setFollowUpCount((c) => c + 1);
        } else {
          setFollowUpCount(0);
        }

        // ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ ì—…ë°ì´íŠ¸
        const nextQuestionCount = questionCount + 1;
        setQuestionCount(nextQuestionCount);
        setCurrentQuestion({
          question_text: response.data.question_text,
          question_type: response.data.question_type,
          question_number: nextQuestionCount
        });
        setAiResponse(response.data.question_text);
        
        // AI ìŒì„± ì„¤ì •
        if (response.audioContent) {
          const audioBlob = new Blob(
            [Uint8Array.from(atob(response.audioContent), c => c.charCodeAt(0))],
            { type: 'audio/mp3' }
          );
          const audioUrl = URL.createObjectURL(audioBlob);
          setAiAudioUrl(audioUrl);
        }
        
        // ë©´ì ‘ ë‹¨ê³„ ì—…ë°ì´íŠ¸
        if (response.data.is_follow_up) {
          setInterviewStage('follow_up_question');
        } else if (taskType === 'initial_question') {
          setInterviewStage('next_question');
        } else {
          setInterviewStage('next_question');
        }
      } else {
        throw new Error(response.error || 'ë‹¤ìŒ ì§ˆë¬¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
      }
    } catch (err) {
      console.error('ë‹¤ìŒ ì§ˆë¬¸ ìƒì„± ì˜¤ë¥˜:', err);
      setError('ë‹¤ìŒ ì§ˆë¬¸ì„ ìƒì„±í•˜ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
    }
  };

  const handleEndInterview = async () => {
    if (window.confirm('ë©´ì ‘ì„ ì¢…ë£Œí•˜ì‹œê² ìŠµë‹ˆê¹Œ?')) {
      try {
        await aiInterviewAPI.endSession(threadId);
        // ë©´ì ‘ ì¢…ë£Œ í›„ í”¼ë“œë°± í˜ì´ì§€ë¡œ ì´ë™
        // ì„ íƒí•œ ê¸°ì—… ì •ë³´ ì •ë¦¬
        localStorage.removeItem('ai_selected_company_id');
        localStorage.removeItem('ai_selected_company_name');
        const userStr = localStorage.getItem('user');
        const user = userStr ? JSON.parse(userStr) : null;
        const user_info = { name: user?.nickname || user?.name || 'ì‚¬ìš©ì' };
        navigate('/ai-interview/final-report', {
          state: {
            user_info,
            interview_data_log: interviewLog,
          }
        });
      } catch (err) {
        setError('ë©´ì ‘ì„ ì¢…ë£Œí•˜ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
        console.error('Error ending session:', err);
      }
    }
  };

  const handlePauseInterview = () => {
    navigate('/ai-interview');
  };

  if (loading) {
    return (
      <Layout>
        <div className="container">
          <div className="ai-interview-room-container">
            <div className="loading">ë©´ì ‘ì‹¤ì„ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤...</div>
          </div>
        </div>
      </Layout>
    );
  }

  if (error && !session) {
    return (
      <Layout>
        <div className="container">
          <div className="ai-interview-room-container">
            <div className="error">{error}</div>
            <button onClick={() => navigate('/ai-interview')} className="back-btn">
              ëª©ë¡ìœ¼ë¡œ ëŒì•„ê°€ê¸°
            </button>
          </div>
        </div>
      </Layout>
    );
  }

  return (
    <Layout>
      <div className="container ai-interview-room-container">
      <div className="interview-header">
        <div className="company-info">
          <h2>{localStorage.getItem('ai_selected_company_name') || 'ê¸°ì—…ëª… ì—†ìŒ'}</h2>
          <p>AI ë©´ì ‘ ì§„í–‰ ì¤‘</p>
        </div>
        
        <div className="session-info">
          <span className="question-counter">
            {questionCount} / {MAX_TOTAL_QUESTIONS}
          </span>
          <span className="interview-stage">
            {interviewStage === 'self_introduction_request' ? 'ìê¸°ì†Œê°œ ìš”ì²­' :
             interviewStage === 'initial_question' ? 'ì´ˆê¸° ì§ˆë¬¸' :
             interviewStage === 'next_question' ? 'ë‹¤ìŒ ì§ˆë¬¸' :
             interviewStage === 'follow_up_question' ? 'ì‹¬í™” ì§ˆë¬¸' :
             interviewStage === 'final' ? 'ë§ˆë¬´ë¦¬' : 'ì§„í–‰ì¤‘'}
          </span>
        </div>

        <div className="interview-controls">
          <button onClick={handlePauseInterview} className="pause-btn">
            ì¼ì‹œì •ì§€
          </button>
          <button onClick={handleEndInterview} className="end-btn">
            ë©´ì ‘ ì¢…ë£Œ
          </button>
        </div>
      </div>

      <div className="interview-content">
        {currentQuestion ? (
          <div className="question-section">
            <div className="question-card">
              <div className="question-header">
                <span className="question-type">{currentQuestion.question_type}</span>
                <span className="question-number">
                  {interviewStage === 'self_introduction_request' ? 'ìê¸°ì†Œê°œ ìš”ì²­' : `ì§ˆë¬¸ ${currentQuestion.question_number}`}
                </span>
              </div>
              <h3 className="question-text">{currentQuestion.question_text}</h3>
            </div>
            
            {aiAudioUrl && (
              <div className="ai-audio-controls">
                <button 
                  onClick={() => {
                    const audio = new Audio(aiAudioUrl);
                    audio.play();
                  }}
                  className="play-ai-audio-btn"
                >
                  ğŸ”Š AI ìŒì„± ë‹¤ì‹œ ë“£ê¸°
                </button>
              </div>
            )}
          </div>
        ) : (
          <div className="no-question">
            <p>ì§ˆë¬¸ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤...</p>
          </div>
        )}

        <div className="answer-section">
          <div className="transcription-area">
            <h4>ë‹µë³€ ë‚´ìš©</h4>
            <div className="transcription-text">
              {transcription || 'ìŒì„±ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”...'}
            </div>
          </div>

          <div className="recording-controls">
            {!isRecording && !isProcessing ? (
              <button onClick={startRecording} className="record-btn">
                ğŸ¤ ë‹µë³€ ì‹œì‘
              </button>
            ) : isRecording ? (
              <button onClick={stopRecording} className="stop-btn">
                â¹ï¸ ë‹µë³€ ì™„ë£Œ
              </button>
            ) : (
              <div className="processing">
                <div className="spinner"></div>
                <p>ë‹µë³€ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...</p>
              </div>
            )}
          </div>
        </div>
      </div>

      {error && (
        <div className="error-message">
          {error}
          <button onClick={() => setError(null)} className="close-error">
            âœ•
          </button>
        </div>
      )}

      <div className="interview-tips">
        <h4>ë©´ì ‘ íŒ</h4>
        <ul>
          <li>ëª…í™•í•˜ê³  ìì‹ ê° ìˆê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.</li>
          <li>êµ¬ì²´ì ì¸ ê²½í—˜ê³¼ ì˜ˆì‹œë¥¼ ë“¤ì–´ ì„¤ëª…í•˜ì„¸ìš”.</li>
          <li>ë‹µë³€ í›„ "ë‹µë³€ ì™„ë£Œ" ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.</li>
          <li>ë©´ì ‘ ì¤‘ ì–¸ì œë“ ì§€ ì¼ì‹œì •ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</li>
          {interviewStage === 'self_introduction_request' && (
            <li>ë¨¼ì € ê°„ë‹¨í•œ ìê¸°ì†Œê°œë¥¼ í•´ì£¼ì„¸ìš”.</li>
          )}
        </ul>
      </div>
      </div>
    </Layout>
  );
};

export default AIInterviewRoom;
